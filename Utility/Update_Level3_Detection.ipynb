{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18eadfae-8fa1-48df-bf94-498cd2296e9d",
   "metadata": {},
   "source": [
    "# Generate Asteroid CSV for Calibration Level 2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982df571-d061-43e5-a705-d2615a577af4",
   "metadata": {},
   "source": [
    "This code streamlines the process of identifying new asteroid detections in the MIRI database by focusing exclusively on observations that have not yet been processed. It compares the observations in the current MIRI database with those recorded in the previously generated 'Level3_Asteroid_Search.csv'. Any new observations that were not included in the initial search are processed using the Level 3 detection pipeline. The results of this incremental search are then appended to an updated CSV, creating an updated and comprehensive dataset of asteroid detections. This approach avoids reprocessing already-searched data, significantly reducing runtime and improving efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca155fa-75a5-4374-859c-976da41c0b3d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e870ba2-8a59-4258-b3b4-1fe9c409aa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import glob\n",
    "\n",
    "import shapely.wkt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from PIL import Image\n",
    "from sbident import SBIdent\n",
    "\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.time import Time\n",
    "import astropy.units as u\n",
    "from astropy.visualization import simple_norm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from astroquery.jplhorizons import Horizons\n",
    "from astroquery.esa.jwst import Jwst\n",
    "\n",
    "from scipy.ndimage import label\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144fadc-7440-4b78-b5ac-6ebd49456b4c",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c04583-87ea-49b6-832b-b65bc6624e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def MJDconversion(modifiedJulianDate):\n",
    "    # Convert string from Modified Julian Date to YYYMMDD [HH:MM:SS.SS] format\n",
    "    return (Time(modifiedJulianDate, format='mjd').iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144c4fe9-a29e-4a0b-8e6f-f74a64a2378c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_strings(string_list):\n",
    "    # Convert a list of strings into a single string comma seperated\n",
    "    return ', '.join(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6edae84-3be3-4021-bb5a-ae225687a7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def members_string(members_init_string):\n",
    "    # Convert 'members' string from the archive query into a more presentable fashion of level 3 CSV\n",
    "    members_string = members_init_string.replace('caom:JWST/', '').replace(' ',', ')\n",
    "    return (members_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9632bf-f4cf-4cb7-9bdc-a86cfce676f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def checkDataExists(proposal, observation):\n",
    "    # Check if the observation is on Datalabs\n",
    "    jwst_file = f\"jw0{next(c for c in proposal if c != '0')}\"\n",
    "    dataPath = f'/data/user/jwst_{jwst_file}/jw0{proposal}/{observation}_i2d.fits.gz'    \n",
    "    return (os.path.exists(dataPath))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a3689f6-4d8e-4735-ba82-4a4a51076e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HiddenPrints:\n",
    "    # Does not produce print outputs, used for built in functions with noisy print statmeents\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b77e8f88-f39e-4fe9-823f-926b615d4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_files(CSV1, CSV2, folder_path):        \n",
    "    # List to store dataframes\n",
    "    added_CSV = [CSV1, CSV2]\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    combined_df = pd.concat(added_CSV, ignore_index=True)\n",
    "    combined_df = combined_df.sort_values('Observation', ascending=True)\n",
    "    \n",
    "    # Save combined dataframe to output CSV\n",
    "    combined_df.to_csv(f\"{folder_path}/Updated_Level3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f4aa1a-b4c3-4e48-b726-76a015c7a602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def formatPolygon(polyString):\n",
    "    # Format the archive polygon string to a format that is compatible with the shapely function\n",
    "    #slice away the polygon charactors 'polygon((' from the start and '))' from the end\n",
    "    coords = polyString[8:-2].split(' ')\n",
    "    \n",
    "    #Add in the fist location at the end to close the 4 point region, shapely expects 5 coordinates\n",
    "    coords.append(coords[0])\n",
    "    coords.append(coords[1])\n",
    "    \n",
    "    return f\"POLYGON (({', '.join([coords[i] + ' ' + coords[i+1] for i in range(0, len(coords), 2)])}))\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abab3c95-000e-4d44-81e5-7687736f7ede",
   "metadata": {},
   "source": [
    "## Archive Query Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75f0b4d-7d61-4541-9e2c-c9b86f7ff4c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def queryArchive(volume, readouts, query_filters):\n",
    "    # Generate an adql query search for the JWST archive to filter the observations and produce a pandas DF containing all useful information\n",
    "    \n",
    "    # Set up constraints and filters for data selected for the archive to return\n",
    "    query_string = f\"SELECT {','.join(readouts)} FROM jwst.{volume} WHERE {' AND '.join(query_filters)}\"\n",
    "    \n",
    "    # Run job and convert archive results to a pandas dataframe \n",
    "    job = Jwst.launch_job(query_string, async_job=True)\n",
    "    panda_result = job.get_results().to_pandas()\n",
    "        \n",
    "    #Sort the dataframe by the proposal ID\n",
    "    return panda_result.sort_values(by=['observationid']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa197830-4c75-4360-842d-094f95845493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def level3_Archive_Query(propRange = [1000,9000], instrumentName = 'MIRI/IMAGE', dataType = 'image', volume = 'archive', additionalFilters = []):\n",
    "    \"\"\"\n",
    "    --- Filter Search Parameters --- \n",
    "    propRange = list containing the starting and ending proposal range to check\n",
    "    instrumentName = instrument used for observation\n",
    "    datatype =  observation data type\n",
    "    volume = volume used for database search\n",
    "    additionalFilters = list of strings containing additional filters to be used in the archive filtering\n",
    "    \"\"\"\n",
    "    \n",
    "    lowerbound_proposal, upperbound_proposal = propRange\n",
    "    \n",
    "    calLVL = 3\n",
    "    \n",
    "    # Define query filters\n",
    "    query_filters = [\n",
    "            f'jwst.{volume}.calibrationlevel = {calLVL}',\n",
    "            f\"jwst.{volume}.dataproducttype = '{dataType}'\",\n",
    "            f\"jwst.{volume}.instrument_name = '{instrumentName}'\",\n",
    "            f\"jwst.{volume}.proposal_id >= '{lowerbound_proposal}'\",\n",
    "            f\"jwst.{volume}.proposal_id <= '{upperbound_proposal}'\",\n",
    "        ] + additionalFilters  # Append additional filters if provided\n",
    "    \n",
    "    # Define which archive outputs of interest\n",
    "    query_topics = ['proposal_id',  'observationid', 'dataproducttype', 'intent',  'instrument_name',  'energy_bandpassname',\n",
    "                   'target_moving','position_bounds_spoly','time_bounds_lower','time_bounds_upper','members']\n",
    "    \n",
    "    # Run the search, return a dataframe with results\n",
    "    with HiddenPrints():\n",
    "        level3_ArchiveDF = queryArchive(volume, query_topics, query_filters)\n",
    "    \n",
    "    return (level3_ArchiveDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b06ff-c0ac-4db2-b53a-d1a3d9cca650",
   "metadata": {},
   "source": [
    "## Small Body Identification Cone Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08881c9-9967-45f3-9cf0-fbe1dda2ceaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def definePolyEdges(polyString):\n",
    "    # Define the image boundaries for the cone search\n",
    "    # NOTE: the cone search takes RA and DEC bounds so image bounds are aligned with the DEC and RA axis (using the min,max bounds)\n",
    "    \n",
    "    # Deconstruct the polygon string into its RA and DEC coordinates \n",
    "    coordinates = polyString.replace(\"POLYGON ((\", \"\").replace(\"))\", \"\").replace(\", \", \" \").split()\n",
    "    coordinates = list(map(float, coordinates))\n",
    "    \n",
    "    RA_elements = coordinates[::2]\n",
    "    DEC_elements = coordinates[1::2]\n",
    "    \n",
    "    # Add in a small buffer around the image \n",
    "    buffer = 0.005  #Deg\n",
    "\n",
    "    # Identify the max/min boundary range of the image by identifying 2 corners of the image\n",
    "    low_right_corner = SkyCoord(min(RA_elements) - buffer, min(DEC_elements) - buffer, frame='icrs', unit='deg')\n",
    "    up_left_corner   = SkyCoord(max(RA_elements) + buffer, max(DEC_elements) + buffer, frame='icrs', unit='deg')\n",
    "    \n",
    "    return([low_right_corner, up_left_corner])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30307082-d966-4692-9258-cd0b00cc90f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expProbeTime(expStartMJD, expEndMJD):\n",
    "    # For longer exposure times, define probe times to cone search for streaking asteroids\n",
    "    probe_time = (1/3)/24 #20 minutes\n",
    "    \n",
    "    # Check how many 20 minute segments are in the exposure time\n",
    "    probe = expStartMJD  + probe_time\n",
    "    \n",
    "    if (expEndMJD - expStartMJD) > probe:\n",
    "        probe_list = [expStartMJD]\n",
    "        \n",
    "        while probe < expEndMJD:\n",
    "            probe_list.append(MJDconversion(probe + probe_time))\n",
    "            probe += probe_time\n",
    "        \n",
    "    else:\n",
    "        # Choose the center of the exposure time\n",
    "        probe_list = [MJDconversion(expStartMJD + (expEndMJD - expStartMJD)/2)]\n",
    "        \n",
    "    # Return a list containing all of the 20 minute times during the exposure time to be cone searched over\n",
    "    return (probe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b52bf562-9a79-495d-9309-1bce760e9020",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def JWSTposition(obsTime):\n",
    "    # Determine the position of JWST during the observation time from an Earth perspective\n",
    "    # Follows example 3 from https://github.com/bengebre/sbident/blob/main/examples/sbident-examples.ipynb \n",
    "    \n",
    "    #NOTE: it is likely that this value can be pulled from the image header in the future\n",
    "    \n",
    "    # Generate AU to km conversion\n",
    "    au_to_km = (1 * u.au).to(u.km).value\n",
    "    \n",
    "    # Probe for the JWST output from JPL Horizons, state vector\n",
    "    jwst_output = Horizons(id='JWST',location='Geocentric',epochs=obsTime.jd, id_type='id').vectors(refplane='earth')\n",
    "\n",
    "    # Convert position and velocity from AU to km and km/s respectively\n",
    "    jwst_output_km = jwst_output[['x', 'y', 'z', 'vx', 'vy', 'vz']].to_pandas().to_numpy()\n",
    "    jwst_output_km[:, :3] *= au_to_km  # Convert position (x, y, z) from AU to km\n",
    "    jwst_output_km[:, 3:] /= 86400     # Convert velocity (vx, vy, vz) from AU/day to km/s\n",
    "\n",
    "    # Form the xobs dictionary that is the input for SBIdent location argument\n",
    "    xobs = ','.join([f\"{s:.12e}\" for s in jwst_output_km[0]])\n",
    "    return {'xobs': xobs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3089c92-abe7-4b7a-9130-d436f2b452ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coneSearch(Exptime, Edge1, Edge2):\n",
    "    # Apply cone search method to identify what asteroids are present in the observation at a specific time (exp time) bound by the image corners (ra, dec)\n",
    "    # NOTE: unlike JPL Horizons, the sbident cone search only utilizes 1 fixed time\n",
    "    \n",
    "    # Convert the exposure time string into the observation time to probe the cone search\n",
    "    ObsTime = Time(Exptime)\n",
    "    \n",
    "    # Determine the JWST position at the moment of observation\n",
    "    jwstLocation = JWSTposition(ObsTime)\n",
    "\n",
    "    # Apply the small body identification cone search method 'sbid' from https://github.com/bengebre/sbident\n",
    "    try:\n",
    "        sbid = SBIdent(jwstLocation, ObsTime, [Edge1, Edge2]).results\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Some times the connection gets interrupted and needs to be reran\n",
    "        logging.info(\"Failed First Try in SBIDENT\")\n",
    "        logging.info(e)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Try again\n",
    "        try:\n",
    "            sbid = SBIdent(jwstLocation, ObsTime, [Edge1, Edge2]).results\n",
    "        except Exception as e:\n",
    "            logging.info(\"Failed Second Try in SBIDENT\")\n",
    "            logging.info(e)\n",
    "            sbid = False\n",
    "    \n",
    "    # If the return sbid is an empty list convert it to a False boolean\n",
    "    if isinstance(sbid, list) and not sbid:\n",
    "        logging.info(\"SBIDENT Output was empty\")\n",
    "        sbid = False\n",
    "    \n",
    "    return(sbid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570e52e-5a28-482b-9fdf-28acfb4b11c5",
   "metadata": {},
   "source": [
    "## Level 3 Asteroid Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f32a84e-81f5-48a4-b904-52e66c942968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def level3_asteroid_names(expStartMJD, expEndMJD, polyStringFormatted):\n",
    "    # Return all the asteroid names within the level 3 image conesearch\n",
    "    \n",
    "    # Define the image bounds from the polygon\n",
    "    poly_corners = definePolyEdges(polyStringFormatted)\n",
    "    \n",
    "    # Define the probe time for individual searches\n",
    "    probeList = expProbeTime(expStartMJD, expEndMJD)\n",
    "    \n",
    "    asteroid_names = []\n",
    "    \n",
    "    # Loop over the probe times within an image and return all asteroid names from the conesearch\n",
    "    for probe in probeList:\n",
    "        sbid_middle_results = coneSearch(probe, *poly_corners)\n",
    "        \n",
    "        if sbid_middle_results:\n",
    "            asteroid_names.append(sbid_middle_results['Object name']) \n",
    "        else:\n",
    "            # No asteroids found in the cone search\n",
    "            pass\n",
    "    \n",
    "    # Find only uniqely contained Asteroids\n",
    "    unique_asteroids = list(set(item.split('(')[-1].replace(')', '') for sublist in asteroid_names for item in sublist))\n",
    "\n",
    "    if len(unique_asteroids) > 0:\n",
    "        return(', '.join([f\"{ast}\" for ast in unique_asteroids]))\n",
    "\n",
    "    else:\n",
    "        # No Asteroids found\n",
    "        return('')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01ffbff-b405-454a-b6ce-04094c6f39cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def level3_asteroid_search(row):\n",
    "    #Begin the asteroid search process \n",
    "    \n",
    "    proposal = row['proposal_id']\n",
    "    observation = row['observationid']\n",
    "    polygonString = row['position_bounds_spoly']\n",
    "    expStartMJD = row['time_bounds_lower']\n",
    "    expEndMJD = row['time_bounds_upper']\n",
    "\n",
    "    #convert the format of the polygon string\n",
    "    poly_string_formatted = formatPolygon(str(polygonString))\n",
    "    \n",
    "    #perform the initial Cone Search\n",
    "    sbident_asteroids = level3_asteroid_names(expStartMJD, expEndMJD, poly_string_formatted)\n",
    "        \n",
    "    return(sbident_asteroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d0328-0e04-4208-8680-89f3cd70efbb",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fb54a9b-4768-4f01-8e11-c36276d62c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(propRange, instrumentName, dataType, volume, additionalFilters=[], level3_CSV_Input_Path = ''):\n",
    "    # Main function to run the JWST Known-Asteroid Detection\n",
    "    if '/' in level3_CSV_Input_Path:\n",
    "        folder_path = os.path.dirname(level3_CSV_Input_Path)\n",
    "    else:\n",
    "        folder_path = './'\n",
    "    current_time = datetime.now()\n",
    "    timestamp = current_time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_filename = f\"{folder_path}/LVL3_Update_log_{timestamp}.txt\"\n",
    "\n",
    "    # Configure logging to write to a file\n",
    "    logging.basicConfig(\n",
    "        filename=log_filename,  # Log file\n",
    "        level=logging.INFO,     # Logging level\n",
    "        force=True,             #prevent overwriting data\n",
    "        format=\"%(message)s\"    # Log message format\n",
    "    )\n",
    "\n",
    "    # Log messages (these will go to the file only)\n",
    "    logging.info(f\"This run was performed at {timestamp}\\n\")\n",
    "    \n",
    "    ##### ----- LEVEL 3 ----- #####\n",
    "    \n",
    "    \n",
    "    # If the Level 3 CSV has already been generated then dont rerun it\n",
    "    if level3_CSV_Input_Path == '':\n",
    "        print('Missing previously generated Level 3 CSV')\n",
    "        \n",
    "    else:\n",
    "        start_time = time.time()\n",
    "        logging.info('Performing Level 3 Search')\n",
    "        \n",
    "        # read in previous Level 3 CSV\n",
    "        Level_3_Archive_CSV = pd.read_csv(level3_CSV_Input_Path)\n",
    "        \n",
    "        # Extract the 'Observation' column as a list\n",
    "        observation_list = Level_3_Archive_CSV['Observation'].tolist()\n",
    "\n",
    "        # Perform an archive search for level 3 observations meeting the qualifications defined in the main function\n",
    "        Level_3_Archive_DF = level3_Archive_Query(propRange, instrumentName, dataType, volume, additionalFilters)\n",
    "        \n",
    "        # Only looking at observations not previously scanned \n",
    "        Filtered_Level_3_Archive_DF = Level_3_Archive_DF[~Level_3_Archive_DF['observationid'].isin(observation_list)]\n",
    "        \n",
    "        if Filtered_Level_3_Archive_DF.empty:\n",
    "            print(f\"Archive does not contain more observations then previously scanned, in range {propRange}\")\n",
    "            logging.info(f'Archive does not contain more observations then previously scanned, in range {propRange}')\n",
    "            return\n",
    "        \n",
    "        # Itterate through the level 3 archive data and check images for asteroids\n",
    "        Filtered_Level_3_Archive_DF['Asteroids'] = Filtered_Level_3_Archive_DF.progress_apply(lambda row: pd.Series(level3_asteroid_search(row)), axis=1)\n",
    "\n",
    "        # Prepare Data Frame for CSV presentation\n",
    "        Level_3_Archive_CSV_new = (\n",
    "            Filtered_Level_3_Archive_DF.rename(columns={\n",
    "                'proposal_id': 'Proposal', \n",
    "                'observationid': 'Observation', \n",
    "                'dataproducttype': 'Data Type',\n",
    "                'intent': 'Intent',\n",
    "                'instrument_name': 'Instrument',\n",
    "                'energy_bandpassname': 'Filter',\n",
    "                'target_moving': 'Moving', \n",
    "                'position_bounds_spoly': 'Polygon Boundary', \n",
    "                'time_bounds_lower': 'Exposure Start', \n",
    "                'time_bounds_upper': 'Exposure End',\n",
    "                'members': 'Level 2 Members'\n",
    "            })\n",
    "\n",
    "            .assign(**{\n",
    "                'Exposure Start': lambda df: df['Exposure Start'].apply(MJDconversion),                                     # Convert from MJD to 'yyyy-mm-dd HH:MM:SS'\n",
    "                'Exposure End': lambda df: df['Exposure End'].apply(MJDconversion),                                         # Convert from MJD to 'yyyy-mm-dd HH:MM:SS'\n",
    "                'Moving': lambda df: df['Moving'].replace({0: 'No', 1: 'Yes'}),                                             # Adds Yes/No if the observation is 'moving'\n",
    "                'Datalabs': lambda df: df.apply(lambda row: checkDataExists(row['Proposal'], row['Observation']),axis=1),   # Add 'data_exists' column tracking if the img is on Datalabs\n",
    "                'Level 2 Members': lambda df: df['Level 2 Members'].apply(members_string)})                                 # Configure the 'members' format\n",
    "            .sort_values(by='Observation', ascending=True)                                                                  # Sort by Observation ID\n",
    "            .reset_index(drop=True))                                                                                        # Reset the index\n",
    "\n",
    "        # Save CSV\n",
    "        Level_3_Archive_CSV_new.to_csv(f\"{folder_path}/Level3_New_Obs.csv\",index=False)\n",
    "\n",
    "        # Reduce dataframe to only observations with asteroids, save CSV\n",
    "        Level_3_Archive_CSV_Only_Asteroids = Level_3_Archive_CSV_new[Level_3_Archive_CSV_new['Asteroids'].str.contains(r'[a-zA-Z]', na=False)].copy()\n",
    "        Level_3_Archive_CSV_Only_Asteroids.to_csv(f\"{folder_path}/Level3_New_Obs_Asteroids.csv\",index=False)\n",
    "        \n",
    "        logging.info(f'Finished the Level 3 Search:')\n",
    "        logging.info(f'From {len(Level_3_Archive_CSV_new)} Searched Observations')\n",
    "        logging.info(f'{len(Level_3_Archive_CSV_Only_Asteroids)} Observations contained atleast 1 Asteroid')\n",
    "        logging.info(f'This took {round((time.time()- start_time)/60)} minutes\\n')\n",
    "        \n",
    "        logging.info(f'Updated the new CSV, saved to {folder_path}/Level3_Updated.csv\\n')\n",
    "        combine_csv_files(Level_3_Archive_CSV, Level_3_Archive_CSV_new, folder_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f0cb8-5840-4ac2-b160-0a61e2c2acb3",
   "metadata": {},
   "source": [
    "## Run The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ae5beb-0704-47d1-a5e9-3f6894106883",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        jw01022-o017_t001_miri_f770w\n",
      "1        jw01022-o018_t001_miri_f770w\n",
      "2        jw01022-o019_t001_miri_f770w\n",
      "3        jw01022-o020_t001_miri_f770w\n",
      "4        jw01022-o021_t001_miri_f770w\n",
      "                    ...              \n",
      "6008     jw06811-o001_t001_miri_f770w\n",
      "6009    jw06838-o004_t001_miri_f1280w\n",
      "6010    jw06838-o004_t001_miri_f1500w\n",
      "6011    jw06838-o004_t001_miri_f1800w\n",
      "6012    jw06838-o004_t001_miri_f2100w\n",
      "Name: observationid, Length: 6013, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a45255d46a41999766715ebd8b05a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.13 s, sys: 138 ms, total: 1.27 s\n",
      "Wall time: 36min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Constants and parameters\n",
    "starting_proposal = 1000\n",
    "ending_proposal = 7000\n",
    "\n",
    "instrument = 'MIRI/IMAGE'\n",
    "data_type = 'image'\n",
    "volume = 'archive'\n",
    "\n",
    "proposal_range = [starting_proposal,ending_proposal]\n",
    "\n",
    "main(proposal_range, instrument, data_type, volume, level3_CSV_Input_Path = 'Results/Level3_Asteroid_Search_Full.csv')\n",
    "\n",
    "#Kernel keeps restarting at 1177, 1161\n",
    "# check the uncertainty in position for far and close (1727 streak accidentally picks up a different source)2015 XK95"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nik_Asteroid",
   "language": "python",
   "name": "nik_asteroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
