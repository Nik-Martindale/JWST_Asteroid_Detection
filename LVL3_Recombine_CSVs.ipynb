{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df3e95b0-a99e-4762-9d77-e1487307bc72",
   "metadata": {},
   "source": [
    "## Combine CSV script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12e0e61-4f8d-4d58-b4e1-f7636b50bc56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9c122-20e1-45bb-a4f4-1fc3e7e7ea08",
   "metadata": {},
   "source": [
    "# Combine Asteroid CSVs into a single Full.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc86a7da-545d-4809-9242-3eac2231566e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Get all CSV files in the current directory that start with 'LVL2_Asteroids'\n",
    "def get_csv_files(path):\n",
    "    csv_files = [f'{path}/{f}' for f in os.listdir(path) if f.startswith('LVL2_Asteroids') and f.endswith('.csv') and 'Seg' not in f]\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1540742-2804-4456-b996-40e3417981f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Combine all CSV files into one dataframe\n",
    "def combine_csv_files(csv_files):\n",
    "    combined_df = pd.DataFrame()  # Empty DataFrame to hold all data\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)  # Read each CSV file\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)  # Append to the combined dataframe\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed1a315-49bc-4930-88a4-2ab73260451b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Remove duplicate rows based on the 'Observation' column\n",
    "def remove_duplicates(combined_df):\n",
    "    # Drop duplicates based on the 'Observation' column\n",
    "    combined_df = combined_df.drop_duplicates(subset='Observation', keep='first')\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "176c5da7-b976-4c22-bf13-1359e0d7881b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Save the combined DataFrame to a new CSV file\n",
    "def save_combined_csv(combined_df, output_file):\n",
    "    combined_df.to_csv(output_file, index=False)  # Save without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "922b6444-668e-4740-842c-adfa3c1ecc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file saved as 'LVL3_Full.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Main function to execute the script\n",
    "def main(path):\n",
    "    csv_files = get_csv_files(path)  # Get all CSV files starting with 'LVL2_Asteroids'\n",
    "\n",
    "    if csv_files:  # Check if any matching CSV files are found\n",
    "        combined_df = combine_csv_files(csv_files)  # Combine all CSV files\n",
    "        combined_df = remove_duplicates(combined_df)  # Remove duplicate rows based on 'Observation'\n",
    "        combined_df = combined_df.sort_values(by=['Observation']) \n",
    "        save_combined_csv(combined_df, 'LVL2_Full.csv')  # Save the result to 'LVL2_Full.csv'\n",
    "\n",
    "        print(f\"Combined CSV file saved as 'LVL3_Full.csv'.\")\n",
    "    else:\n",
    "        print(\"No matching CSV files found.\")\n",
    "\n",
    "main('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01e9be-c66c-402e-bb56-74bd765164ce",
   "metadata": {},
   "source": [
    "## Generate new CSV containing only the asteroid rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb5dab9c-115b-4945-891a-6ccbf135c99d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered CSV saved as 'LVL2_Only_Asteroids_NONMOVING.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Read the original CSV file ('CSV1')\n",
    "def filter_asteroids(csv_file):\n",
    "    df = pd.read_csv(csv_file)  # Read the CSV into a DataFrame\n",
    "    \n",
    "    # Step 2: Filter rows where the 'Asteroids' column contains '['\n",
    "    filtered_df = df[df['Asteroids'].str.contains(r'\\[', na=False)]# & ~df['Asteroids'].str.contains(r'\\[', na=False)]  # Use regex to match '[' in 'Asteroids' column\n",
    "\n",
    "    return filtered_df\n",
    "\n",
    "# Step 3: Save the filtered rows to a new CSV file ('CSV2')\n",
    "def save_filtered_csv(filtered_df, output_file):\n",
    "    filtered_df.to_csv(output_file, index=False)  # Save without index\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    input_csv = 'LVL2_Full.csv'  # Replace with your input CSV filename\n",
    "    output_csv = 'LVL2_Only_Asteroids.csv'  # Output CSV filename\n",
    "\n",
    "    filtered_df = filter_asteroids(input_csv)  # Get the filtered DataFrame\n",
    "    save_filtered_csv(filtered_df, output_csv)  # Save it to 'CSV2.csv'\n",
    "\n",
    "    print(f\"Filtered CSV saved as '{output_csv}'.\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7375bcb9-cc4b-47e9-8f20-bfe99fff3dad",
   "metadata": {},
   "source": [
    "# Compare the new method for combining csvs to the old output  (looking at rows that are different/ dont exist in both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75083227-9dc8-4764-8683-fa6381b7c182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where 'Moving' is 'Yes' in CSV 2 but not in CSV 1 -109-:\n",
      "      Proposal                    Observation Instrument  Filter Moving  \\\n",
      "0         1022   jw01022-o017_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "1         1022   jw01022-o018_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "2         1022   jw01022-o019_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "3         1022   jw01022-o020_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "4         1022   jw01022-o021_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "...        ...                            ...        ...     ...    ...   \n",
      "1985      1897  jw01897-o003_t001_miri_f1130w       MIRI  F1130W    Yes   \n",
      "1986      1897   jw01897-o003_t001_miri_f770w       MIRI   F770W    Yes   \n",
      "1987      1897  jw01897-o004_t002_miri_f1000w       MIRI  F1000W    Yes   \n",
      "1988      1897  jw01897-o004_t002_miri_f1130w       MIRI  F1130W    Yes   \n",
      "1989      1897   jw01897-o004_t002_miri_f770w       MIRI   F770W    Yes   \n",
      "\n",
      "                                                Polygon  \\\n",
      "0     Polygon 7.306766479999976 1.7644805879999972 7...   \n",
      "1     Polygon 7.3537626189999825 1.784651949999999 7...   \n",
      "2     Polygon 7.400737578000019 1.804926324000003 7....   \n",
      "3     Polygon 7.451796525999987 1.7902011370000013 7...   \n",
      "4     Polygon 7.472877699999996 1.829822078 7.443093...   \n",
      "...                                                 ...   \n",
      "1985  Polygon 262.14830441299995 -19.147506388000007...   \n",
      "1986  Polygon 262.1590088910001 -19.147328858999995 ...   \n",
      "1987  Polygon 262.1710114000001 -19.19707483899998 2...   \n",
      "1988  Polygon 262.166384431 -19.19715581799998 262.1...   \n",
      "1989  Polygon 262.17687210399987 -19.19697864999999 ...   \n",
      "\n",
      "                    Exp Start                  Exp End       Asteroids  \n",
      "0     2022-07-03 17:11:15.041  2022-07-03 17:11:45.566             NaN  \n",
      "1     2022-07-03 17:31:58.304  2022-07-03 17:32:28.829  ['2014 OL348']  \n",
      "2     2022-07-03 17:53:20.351  2022-07-03 17:53:50.876             NaN  \n",
      "3     2022-07-03 20:12:41.751  2022-07-03 20:13:12.276             NaN  \n",
      "4     2022-07-03 19:04:20.187  2022-07-03 19:04:50.712   ['1999 NP39']  \n",
      "...                       ...                      ...             ...  \n",
      "1985  2023-03-20 21:51:57.322  2023-03-20 22:04:23.844             NaN  \n",
      "1986  2023-03-20 22:33:57.180  2023-03-20 22:54:43.169             NaN  \n",
      "1987  2023-03-20 23:39:26.686  2023-03-20 23:53:24.765             NaN  \n",
      "1988  2023-03-20 23:20:20.549  2023-03-20 23:32:33.182             NaN  \n",
      "1989  2023-03-21 00:01:19.350  2023-03-21 00:22:08.091             NaN  \n",
      "\n",
      "[109 rows x 9 columns]\n",
      "\n",
      "Rows where 'Moving' is 'No' in CSV 2 but not in CSV 1 -377:\n",
      "      Proposal                    Observation Instrument  Filter Moving  \\\n",
      "1765      1762   jw01762-o001_t001_miri_f560w       MIRI   F560W     No   \n",
      "1766      1762   jw01762-o002_t002_miri_f560w       MIRI   F560W     No   \n",
      "1767      1762   jw01762-o004_t004_miri_f560w       MIRI   F560W     No   \n",
      "1768      1762   jw01762-o005_t005_miri_f560w       MIRI   F560W     No   \n",
      "1769      1762   jw01762-o006_t006_miri_f560w       MIRI   F560W     No   \n",
      "...        ...                            ...        ...     ...    ...   \n",
      "2143      2025   jw02025-o002_t002_miri_f770w       MIRI   F770W     No   \n",
      "2144      2025   jw02025-o003_t003_miri_f770w       MIRI   F770W     No   \n",
      "2145      2025  jw02025-o004_t004_miri_f1130w       MIRI  F1130W     No   \n",
      "2146      2025   jw02025-o006_t003_miri_f770w       MIRI   F770W     No   \n",
      "2147      2025   jw02025-o007_t002_miri_f770w       MIRI   F770W     No   \n",
      "\n",
      "                                                Polygon  \\\n",
      "1765  Polygon 259.8094171569997 59.503784148000065 2...   \n",
      "1766  Polygon 258.2998436449999 58.94518719100013 25...   \n",
      "1767  Polygon 258.114682762 59.01404389200006 258.16...   \n",
      "1768  Polygon 261.1935625949998 59.27905569399987 26...   \n",
      "1769  Polygon 260.705732601 59.69802904000002 260.75...   \n",
      "...                                                 ...   \n",
      "2143  Polygon 73.76133802499992 30.361571160999983 7...   \n",
      "2144  Polygon 74.65811005799974 29.84163845100003 74...   \n",
      "2145  Polygon 269.05614690799996 -21.95723106599998 ...   \n",
      "2146  Polygon 74.72657493999976 29.850778703000028 7...   \n",
      "2147  Polygon 73.82957372300012 30.374264298999982 7...   \n",
      "\n",
      "                    Exp Start                  Exp End       Asteroids  \n",
      "1765  2022-07-26 17:32:11.036  2022-07-26 19:46:29.972             NaN  \n",
      "1766  2022-08-05 14:49:42.730  2022-08-05 17:02:46.658             NaN  \n",
      "1767  2022-08-07 16:54:35.654  2022-08-07 19:08:15.678             NaN  \n",
      "1768  2022-08-07 19:33:42.012  2022-08-07 21:46:59.893             NaN  \n",
      "1769  2022-08-07 22:17:06.483  2022-08-08 00:30:18.795             NaN  \n",
      "...                       ...                      ...             ...  \n",
      "2143  2023-03-06 15:45:36.903  2023-03-06 18:34:03.865             NaN  \n",
      "2144  2023-01-26 11:11:33.262  2023-01-26 13:20:02.530             NaN  \n",
      "2145  2022-08-10 00:42:14.170  2022-08-10 02:48:27.439  ['2013 AX137']  \n",
      "2146  2023-10-13 07:30:50.225  2023-10-13 09:50:42.181             NaN  \n",
      "2147  2023-10-14 11:18:51.663  2023-10-14 14:08:19.529             NaN  \n",
      "\n",
      "[377 rows x 9 columns]\n",
      "\n",
      " Total new rows = 486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load both CSV files into dataframes\n",
    "def load_csvs(csv_file1, csv_file2):\n",
    "    df1 = pd.read_csv(csv_file1)  # CSV 1 with 'Observation ID'\n",
    "    df2 = pd.read_csv(csv_file2)  # CSV 2 with 'Observation' and 'Moving'\n",
    "    return df1, df2\n",
    "\n",
    "# Step 2: Find rows where 'Observation' in CSV 2 is not present in 'Observation ID' in CSV 1\n",
    "def find_rows_in_csv2_not_in_csv1(df1, df2):\n",
    "    return df2[~df2['Observation'].isin(df1['Observation ID'])]\n",
    "\n",
    "# Step 3: Split the rows into two DataFrames based on the 'Moving' column ('Yes' and 'No')\n",
    "def split_by_moving(df):\n",
    "    df_moving_yes = df[df['Moving'].str.lower() == 'yes']\n",
    "    df_moving_no = df[df['Moving'].str.lower() == 'no']\n",
    "    return df_moving_yes, df_moving_no\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    csv_file1 = 'Previous/LVL2_Asteroids.csv'  # Replace with the path to your first CSV (with 'Observation ID')\n",
    "    csv_file2 = 'LVL2_Full.csv'  # Replace with the path to your second CSV (with 'Observation' and 'Moving')\n",
    "\n",
    "    # Load both CSVs\n",
    "    df1, df2 = load_csvs(csv_file1, csv_file2)\n",
    "\n",
    "    # Find rows in CSV 2 that are not in CSV 1 based on 'Observation' / 'Observation ID'\n",
    "    df2_not_in_df1 = find_rows_in_csv2_not_in_csv1(df1, df2)\n",
    "\n",
    "    # Split the rows based on the 'Moving' column ('Yes' and 'No')\n",
    "    df_moving_yes, df_moving_no = split_by_moving(df2_not_in_df1)\n",
    "\n",
    "    # Output the resulting DataFrames\n",
    "    print(f\"Rows where 'Moving' is 'Yes' in CSV 2 but not in CSV 1 -{len(df_moving_yes)}-:\")\n",
    "    print(df_moving_yes)\n",
    "    \n",
    "\n",
    "    print(f\"\\nRows where 'Moving' is 'No' in CSV 2 but not in CSV 1 -{len(df_moving_no)}:\")\n",
    "    print(df_moving_no)\n",
    "\n",
    "    return df_moving_yes, df_moving_no\n",
    "\n",
    "\n",
    "df_moving_yes, df_moving_no = main()\n",
    "\n",
    "print(f\"\\n Total new rows = {len(df_moving_yes) + len(df_moving_no)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b78980ad-d238-4aee-a674-bb11e7565df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows from CSV 2 where 'Observation' is not present in CSV 1 -486:-\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load both CSV files into dataframes\n",
    "def load_csvs(csv_file1, csv_file2):\n",
    "    df1 = pd.read_csv(csv_file1)  # CSV 1 with 'Observation ID'\n",
    "    df2 = pd.read_csv(csv_file2)  # CSV 2 with 'Observation'\n",
    "    return df1, df2\n",
    "\n",
    "# Step 2: Find all rows in CSV 2 where 'Observation' is not present in 'Observation ID' in CSV 1\n",
    "def find_rows_in_csv2_not_in_csv1(df1, df2):\n",
    "    return df2[~df2['Observation'].isin(df1['Observation ID'])]\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    csv_file1 = 'Previous/LVL2_Asteroids.csv'  # Replace with the path to your first CSV (with 'Observation ID')\n",
    "    csv_file2 = 'LVL2_Full.csv'  # Replace with the path to your second CSV (with 'Observation')\n",
    "\n",
    "    # Load both CSVs\n",
    "    df1, df2 = load_csvs(csv_file1, csv_file2)\n",
    "\n",
    "    # Find rows in CSV 2 that are not in CSV 1 based on 'Observation' / 'Observation ID'\n",
    "    df2_not_in_df1 = find_rows_in_csv2_not_in_csv1(df1, df2)\n",
    "\n",
    "    # Output the resulting DataFrame\n",
    "    print(f\"Rows from CSV 2 where 'Observation' is not present in CSV 1 -{len(df2_not_in_df1)}:-\")\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    \n",
    "    #print(df2_not_in_df1)\n",
    "\n",
    "    return df2_not_in_df1\n",
    "\n",
    "\n",
    "df2_not_in_df1 = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a59dd1-b651-4a96-b84b-33b082c11431",
   "metadata": {},
   "source": [
    "## New proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a86ab3a9-09b2-4f65-8ceb-049e383051eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposals in CSV 2 that are not present in Proposal ID of CSV 1:\n",
      "[1022 1191 1248 1249 1250 1254 1272 1273 1449 1522 1604 1658 1731 1762\n",
      " 1764 1783 1791 1798 1802]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load both CSV files into dataframes\n",
    "def load_csvs(csv_file1, csv_file2):\n",
    "    df1 = pd.read_csv(csv_file1)  # CSV 1 with 'Proposal ID'\n",
    "    df2 = pd.read_csv(csv_file2)  # CSV 2 with 'Proposals'\n",
    "    return df1, df2\n",
    "\n",
    "# Step 2: Find all values in 'Proposals' from CSV 2 that are not present in 'Proposal ID' from CSV 1\n",
    "def find_unique_proposals(df1, df2):\n",
    "    return df2[~df2['Proposal'].isin(df1['Proposal ID'])]\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    csv_file1 = 'Previous/LVL2_Asteroids.csv'  # Replace with the path to your first CSV (with 'Proposal ID')\n",
    "    csv_file2 = 'LVL2_Full.csv'  # Replace with the path to your second CSV (with 'Proposals')\n",
    "\n",
    "    # Load both CSVs\n",
    "    df1, df2 = load_csvs(csv_file1, csv_file2)\n",
    "\n",
    "    # Find values in 'Proposals' (CSV 2) that are not in 'Proposal ID' (CSV 1)\n",
    "    df_unique_proposals = find_unique_proposals(df1, df2)\n",
    "\n",
    "    # Output the resulting DataFrame containing only the unique 'Proposals'\n",
    "    print(\"Proposals in CSV 2 that are not present in Proposal ID of CSV 1:\")\n",
    "    print(df_unique_proposals['Proposal'].unique())\n",
    "\n",
    "    return df_unique_proposals\n",
    "\n",
    "df_unique_proposals = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840a868c-0358-43ed-83aa-3db13f6eae17",
   "metadata": {},
   "source": [
    "# Moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e378dba2-d549-424a-a01f-397836950263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Yes' count in 'Moving' column: 95\n",
      "'No' count in 'Moving' column: 1511\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Open the CSV and count occurrences of 'yes' and 'no' in the 'Moving' column\n",
    "def count_moving_column_values(csv_file):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Ensure the 'Moving' column exists\n",
    "    if 'Moving' not in df.columns:\n",
    "        print(f\"Error: 'Moving' column not found in {csv_file}\")\n",
    "        return\n",
    "    \n",
    "    # Count the occurrences of 'yes' and 'no'\n",
    "    yes_count = df['Moving'].str.lower().value_counts().get('yes', 0)\n",
    "    no_count = df['Moving'].str.lower().value_counts().get('no', 0)\n",
    "\n",
    "    # Return the counts\n",
    "    return yes_count, no_count\n",
    "\n",
    "# Main function to execute the script\n",
    "def main():\n",
    "    csv_file = 'LVL2_Full.csv'  # Replace with the path to your .csv file\n",
    "\n",
    "    # Get the counts of 'yes' and 'no' in the 'Moving' column\n",
    "    yes_count, no_count = count_moving_column_values(csv_file)\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"'Yes' count in 'Moving' column: {yes_count}\")\n",
    "    print(f\"'No' count in 'Moving' column: {no_count}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529f8d4-01e7-419a-96e4-2baf828f715e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f6548-4940-491d-b38d-b46cd4d49416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ffdc7-ecc2-4cc6-b111-33d0bec5ecf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nik_Asteroid",
   "language": "python",
   "name": "nik_asteroid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
